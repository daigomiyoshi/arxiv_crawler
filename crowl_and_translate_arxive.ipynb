{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "from urllib.parse import urlencode\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_url = 'http://export.arxiv.org/api/'\n",
    "\n",
    "keywords = ['cat: stat.ML']\n",
    "start=0\n",
    "max_results = 50\n",
    "sort_by='submittedDate'\n",
    "sort_order=\"descending\"\n",
    "\n",
    "days = 1\n",
    "prune = True\n",
    "debug = False\n",
    "\n",
    "# paper_num_result = []\n",
    "# dict_key_keyword = 'keyword'\n",
    "# dict_key_n_of_papers = 'n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = keywords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_list(root_url, keyword, prune, start, max_results, sort_by, sort_order, days, debug):\n",
    "    result = query(\n",
    "        root_url = root_url,\n",
    "        search_query=keyword,\n",
    "        prune=prune,\n",
    "        start=start,\n",
    "        max_results=max_results,\n",
    "        sort_by=sort_by,\n",
    "        sort_order=sort_order\n",
    "    )\n",
    "    return select_recent_papers(result, days=days, debug=debug)\n",
    "\n",
    "\n",
    "def query(root_url,\n",
    "                  search_query,\n",
    "                  prune,\n",
    "                  start,\n",
    "                  max_results,\n",
    "                  sort_by,\n",
    "                  sort_order):\n",
    "    url_args = urlencode({\"search_query\": search_query,\n",
    "                                          \"start\": start,\n",
    "                                          \"max_results\": max_results,\n",
    "                                          \"sortBy\": sort_by,\n",
    "                                          \"sortOrder\": sort_order})\n",
    "    results = feedparser.parse(root_url + 'query?' + url_args)\n",
    "    if results.get('status') != 200:\n",
    "        raise Exception(\n",
    "            \"HTTP Error \" + str(results.get('status', 'no status')) + \" in query\")\n",
    "    else:\n",
    "        results = results['entries']\n",
    "    for result in results:\n",
    "        modify_query_result(result)\n",
    "        if prune:\n",
    "            prune_query_result(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "def modify_query_result(result):\n",
    "    result['pdf_url'] = None\n",
    "    for link in result['links']:\n",
    "        if 'title' in link and link['title'] == 'pdf':\n",
    "            result['pdf_url'] = link['href']\n",
    "    result['affiliation'] = result.pop('arxiv_affiliation', 'None')\n",
    "    result['arxiv_url'] = result.pop('link')\n",
    "    result['title'] = result['title'].rstrip('\\n')\n",
    "    result['summary'] = result['summary'].rstrip('\\n')\n",
    "    result['authors'] = [d['name'] for d in result['authors']]\n",
    "    if 'arxiv_comment' in result:\n",
    "        result['arxiv_comment'] = result['arxiv_comment'].rstrip('\\n')\n",
    "    else:\n",
    "        result['arxiv_comment'] = None\n",
    "    if 'arxiv_journal_ref' in result:\n",
    "        result['journal_reference'] = result.pop('arxiv_journal_ref')\n",
    "    else:\n",
    "        result['journal_reference'] = None\n",
    "    if 'arxiv_doi' in result:\n",
    "        result['doi'] = result.pop('arxiv_doi')\n",
    "    else:\n",
    "        result['doi'] = None\n",
    "        \n",
    "def prune_query_result(result):\n",
    "    prune_keys = ['updated_parsed',\n",
    "                              'arxiv_primary_category',\n",
    "                              'summary_detail',\n",
    "                              'author',\n",
    "                              'author_detail',\n",
    "                              'links',\n",
    "                              'guidislink',\n",
    "                              'title_detail',\n",
    "                              'tags',\n",
    "                              'id']\n",
    "    for key in prune_keys:\n",
    "        try:\n",
    "            del result[key]\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "def select_recent_papers(from_papers_list, days, debug):\n",
    "    today = datetime.datetime.today()\n",
    "    utc_today = today - relativedelta(hours=9)\n",
    "\n",
    "    from_when = utc_today - relativedelta(days=days)\n",
    "    to_when = utc_today\n",
    "\n",
    "    if debug:\n",
    "        print('JST: ', today)\n",
    "        print('UTC_from: ', from_when)\n",
    "        print('UTC_to  : ', to_when)\n",
    "        print()\n",
    "        print('recent papers\\' timestamps are like below:')\n",
    "        for paper in from_papers_list:\n",
    "            print(paper['published'])\n",
    "\n",
    "    return list(filter(lambda x: condition_to_select_papers(x, from_when, to_when), from_papers_list))\n",
    "\n",
    "def condition_to_select_papers(paper, from_when, to_when):\n",
    "    return from_when <= datetime.datetime(*paper['published_parsed'][:6]) < to_when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for keyword in keywords:\n",
    "    arxiv_lists = make_list(root_url, keyword, prune, start, max_results, sort_by, sort_order, days, debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'updated': '2020-06-03T17:54:26Z',\n",
       " 'published': '2020-06-03T17:54:26Z',\n",
       " 'published_parsed': time.struct_time(tm_year=2020, tm_mon=6, tm_mday=3, tm_hour=17, tm_min=54, tm_sec=26, tm_wday=2, tm_yday=155, tm_isdst=0),\n",
       " 'title': 'Equivariant Flows: exact likelihood generative learning for symmetric\\n  densities',\n",
       " 'summary': 'Normalizing flows are exact-likelihood generative neural networks which\\napproximately transform samples from a simple prior distribution to samples of\\nthe probability distribution of interest. Recent work showed that such\\ngenerative models can be utilized in statistical mechanics to sample\\nequilibrium states of many-body systems in physics and chemistry. To scale and\\ngeneralize these results, it is essential that the natural symmetries in the\\nprobability density - in physics defined by the invariances of the target\\npotential - are built into the flow. We provide a theoretical sufficient\\ncriterion showing that the distribution generated by equivariant normalizing\\nflows is invariant with respect to these symmetries by design. Furthermore, we\\npropose building blocks for flows which preserve symmetries which are usually\\nfound in physical/chemical many-body particle systems. Using benchmark systems\\nmotivated from molecular physics, we demonstrate that those symmetry preserving\\nflows can provide better generalization capabilities and sampling efficiency.',\n",
       " 'authors': ['Jonas Köhler', 'Leon Klein', 'Frank Noé'],\n",
       " 'pdf_url': 'http://arxiv.org/pdf/2006.02425v1',\n",
       " 'affiliation': 'None',\n",
       " 'arxiv_url': 'http://arxiv.org/abs/2006.02425v1',\n",
       " 'arxiv_comment': None,\n",
       " 'journal_reference': None,\n",
       " 'doi': None}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(arxiv_lists))\n",
    "arxiv_lists[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
